{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d1537-68ff-4d44-b4d9-59102ab17c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Function to load datasets\n",
    "def load_data():\n",
    "    (x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = mnist.load_data()\n",
    "    (x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
    "\n",
    "    # Preprocess datasets\n",
    "    x_train_mnist = x_train_mnist.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "    x_test_mnist = x_test_mnist.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "    x_train_fashion = x_train_fashion.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "    x_test_fashion = x_test_fashion.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "    y_train_mnist = to_categorical(y_train_mnist, 10)\n",
    "    y_test_mnist = to_categorical(y_test_mnist, 10)\n",
    "\n",
    "    y_train_fashion = to_categorical(y_train_fashion, 10)\n",
    "    y_test_fashion = to_categorical(y_test_fashion, 10)\n",
    "\n",
    "    return (x_train_mnist, y_train_mnist, x_test_mnist, y_test_mnist), \\\n",
    "           (x_train_fashion, y_train_fashion, x_test_fashion, y_test_fashion)\n",
    "\n",
    "# Simple CNN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate():\n",
    "    # Load data\n",
    "    (x_train_mnist, y_train_mnist, x_test_mnist, y_test_mnist), \\\n",
    "    (x_train_fashion, y_train_fashion, x_test_fashion, y_test_fashion) = load_data()\n",
    "\n",
    "    # Create and train model on MNIST\n",
    "    model_mnist = create_model()\n",
    "    history_mnist = model_mnist.fit(x_train_mnist, y_train_mnist, validation_data=(x_test_mnist, y_test_mnist), epochs=5)\n",
    "\n",
    "    # Create and train model on FashionMNIST\n",
    "    model_fashion = create_model()\n",
    "    history_fashion = model_fashion.fit(x_train_fashion, y_train_fashion, validation_data=(x_test_fashion, y_test_fashion), epochs=5)\n",
    "\n",
    "    # Evaluation\n",
    "    loss_mnist, acc_mnist = model_mnist.evaluate(x_test_mnist, y_test_mnist)\n",
    "    loss_fashion, acc_fashion = model_fashion.evaluate(x_test_fashion, y_test_fashion)\n",
    "\n",
    "    # Predictions and confusion matrices\n",
    "    y_pred_mnist = np.argmax(model_mnist.predict(x_test_mnist), axis=1)\n",
    "    y_true_mnist = np.argmax(y_test_mnist, axis=1)\n",
    "\n",
    "    y_pred_fashion = np.argmax(model_fashion.predict(x_test_fashion), axis=1)\n",
    "    y_true_fashion = np.argmax(y_test_fashion, axis=1)\n",
    "\n",
    "    return (history_mnist, history_fashion), (y_true_mnist, y_pred_mnist), \\\n",
    "           (y_true_fashion, y_pred_fashion)\n",
    "\n",
    "\n",
    "def plot_results(history_mnist, history_fashion, y_true_mnist, y_pred_mnist, y_true_fashion, y_pred_fashion):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "    # Plot MNIST Loss\n",
    "    axes[0, 0].plot(history_mnist.history['loss'], label='Training Loss')\n",
    "    axes[0, 0].plot(history_mnist.history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 0].set_title('MNIST Loss')\n",
    "    axes[0, 0].set_xlabel('Epochs')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "\n",
    "    # Plot FashionMNIST Loss\n",
    "    axes[1, 0].plot(history_fashion.history['loss'], label='Training Loss')\n",
    "    axes[1, 0].plot(history_fashion.history['val_loss'], label='Validation Loss')\n",
    "    axes[1, 0].set_title('FashionMNIST Loss')\n",
    "    axes[1, 0].set_xlabel('Epochs')\n",
    "    axes[1, 0].set_ylabel('Loss')\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "    # Plot MNIST Accuracy\n",
    "    axes[0, 1].plot(history_mnist.history['accuracy'], label='Training Accuracy')\n",
    "    axes[0, 1].plot(history_mnist.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0, 1].set_title('MNIST Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epochs')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "    # Plot FashionMNIST Accuracy\n",
    "    axes[1, 1].plot(history_fashion.history['accuracy'], label='Training Accuracy')\n",
    "    axes[1, 1].plot(history_fashion.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[1, 1].set_title('FashionMNIST Accuracy')\n",
    "    axes[1, 1].set_xlabel('Epochs')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].legend()\n",
    "\n",
    "    # MNIST Confusion Matrix\n",
    "    cm_mnist = confusion_matrix(y_true_mnist, y_pred_mnist)\n",
    "    sns.heatmap(cm_mnist, annot=True, fmt='d', ax=axes[0, 2], cmap='Blues')\n",
    "    axes[0, 2].set_title('MNIST Confusion Matrix')\n",
    "\n",
    "    # FashionMNIST Confusion Matrix\n",
    "    cm_fashion = confusion_matrix(y_true_fashion, y_pred_fashion)\n",
    "    sns.heatmap(cm_fashion, annot=True, fmt='d', ax=axes[1, 2], cmap='Blues')\n",
    "    axes[1, 2].set_title('FashionMNIST Confusion Matrix')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main function to execute the process\n",
    "def main():\n",
    "    (history_mnist, history_fashion), (y_true_mnist, y_pred_mnist), \\\n",
    "    (y_true_fashion, y_pred_fashion) = train_and_evaluate()\n",
    "\n",
    "    # Plot the results\n",
    "    plot_results(history_mnist, history_fashion, y_true_mnist, y_pred_mnist, y_true_fashion, y_pred_fashion)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d610189-c249-4f36-8254-589c45727899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST and FashionMNIST datasets\n",
    "def load_datasets():\n",
    "    (x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = tf.keras.datasets.mnist.load_data()\n",
    "    (x_train_fmnist, y_train_fmnist), (x_test_fmnist, y_test_fmnist) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "    # Normalize and reshape datasets for quantum processing\n",
    "    x_train_mnist = x_train_mnist.astype('float32') / 255.0\n",
    "    x_train_fmnist = x_train_fmnist.astype('float32') / 255.0\n",
    "    x_train_mnist = np.array([x.flatten()[:16] for x in x_train_mnist])  # Use a smaller feature set for quantum input\n",
    "    x_train_fmnist = np.array([x.flatten()[:16] for x in x_train_fmnist])\n",
    "    \n",
    "    return (x_train_mnist, y_train_mnist), (x_train_fmnist, y_train_fmnist)\n",
    "\n",
    "# Quantum Deformable Offset Representation\n",
    "n_qubits = 4  # Number of qubits for the quantum system\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "# Quantum circuit to encode deformable offsets\n",
    "@qml.qnode(dev)\n",
    "def quantum_offset_circuit(offset, weights):\n",
    "    # Encode offset using feature map as quantum state\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(offset[i], wires=i)\n",
    "        qml.RZ(weights[i], wires=i)\n",
    "    \n",
    "    # Entangling layer (non-local gates)\n",
    "    for i in range(n_qubits - 1):\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    \n",
    "    return qml.probs(wires=range(n_qubits))\n",
    "\n",
    "# Cost function using quantum deformable offsets\n",
    "def cost(weights, x_train, y_train):\n",
    "    loss = 0\n",
    "    for i, x in enumerate(x_train):\n",
    "        offset = x  # Quantum feature map for each offset\n",
    "        probs = quantum_offset_circuit(offset, weights)\n",
    "        predicted = np.argmax(probs)\n",
    "        loss += (predicted - y_train[i]) ** 2\n",
    "    return loss / len(x_train)\n",
    "\n",
    "# Training quantum deformable offset model using gradient-based methods\n",
    "def train_quantum_model(x_train, y_train, num_epochs=10, learning_rate=0.1):\n",
    "    weights = np.random.normal(0, np.pi, size=n_qubits, requires_grad=True)\n",
    "    opt = qml.GradientDescentOptimizer(stepsize=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        weights, cost_value = opt.step_and_cost(lambda w: cost(w, x_train, y_train), weights)\n",
    "        print(f\"Epoch {epoch+1}: Cost = {cost_value}\")\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Perform quantum learning on MNIST and FashionMNIST\n",
    "def quantum_learning():\n",
    "    (x_train_mnist, y_train_mnist), (x_train_fmnist, y_train_fmnist) = load_datasets()\n",
    "    \n",
    "    # Train on MNIST\n",
    "    print(\"Training Quantum Deformable Offset Model on MNIST\")\n",
    "    trained_weights_mnist = train_quantum_model(x_train_mnist, y_train_mnist)\n",
    "    \n",
    "    # Train on FashionMNIST\n",
    "    print(\"Training Quantum Deformable Offset Model on FashionMNIST\")\n",
    "    trained_weights_fmnist = train_quantum_model(x_train_fmnist, y_train_fmnist)\n",
    "\n",
    "# Run the quantum learning process\n",
    "quantum_learning()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812eca6-520b-4ba8-ab48-f285f82f9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load MNIST and FashionMNIST datasets\n",
    "def load_data():\n",
    "    (x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = mnist.load_data()\n",
    "    (x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
    "\n",
    "    # Preprocessing: Normalize images to the range [0, 1]\n",
    "    x_test_mnist = x_test_mnist.astype('float32') / 255\n",
    "    x_test_fashion = x_test_fashion.astype('float32') / 255\n",
    "    \n",
    "    return (x_test_mnist, y_test_mnist), (x_test_fashion, y_test_fashion)\n",
    "\n",
    "# Function to calculate PSNR\n",
    "def calculate_psnr(original, processed):\n",
    "    mse = np.mean((original - processed) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    max_pixel = 1.0  # Max pixel value (normalized to 1.0 for the images)\n",
    "    psnr = 10 * np.log10(max_pixel**2 / mse)\n",
    "    return psnr, mse\n",
    "\n",
    "# Function to calculate SNR\n",
    "def calculate_snr(original, processed):\n",
    "    signal_power = np.sum(original ** 2)\n",
    "    noise_power = np.sum((original - processed) ** 2)\n",
    "    snr = 10 * np.log10(signal_power / noise_power)\n",
    "    return snr\n",
    "\n",
    "# Function to calculate SSIM\n",
    "def calculate_ssim(original, processed):\n",
    "    return ssim(original, processed, data_range=processed.max() - processed.min())\n",
    "\n",
    "def quantum_processed_images(original_images):\n",
    "    # For demonstration, we'll assume the processed images are slightly noisy\n",
    "    processed_images = original_images + np.random.normal(0, 0.1, original_images.shape)\n",
    "    processed_images = np.clip(processed_images, 0, 1)  # Ensure pixel values are within [0, 1]\n",
    "    return processed_images\n",
    "\n",
    "# Analyze results for MNIST and FashionMNIST\n",
    "def analyze_results():\n",
    "    (x_test_mnist, y_test_mnist), (x_test_fashion, y_test_fashion) = load_data()\n",
    "\n",
    "    # Simulated quantum processed images (for both datasets)\n",
    "    x_processed_mnist = quantum_processed_images(x_test_mnist)\n",
    "    x_processed_fashion = quantum_processed_images(x_test_fashion)\n",
    "\n",
    "    # Initialize results\n",
    "    results = {\n",
    "        \"Dataset\": [],\n",
    "        \"SNR\": [],\n",
    "        \"PSNR\": [],\n",
    "        \"MSE\": [],\n",
    "        \"SSIM\": []\n",
    "    }\n",
    "\n",
    "    # Evaluate MNIST dataset\n",
    "    snr_mnist = calculate_snr(x_test_mnist, x_processed_mnist)\n",
    "    psnr_mnist, mse_mnist = calculate_psnr(x_test_mnist, x_processed_mnist)\n",
    "    ssim_mnist = calculate_ssim(x_test_mnist[0], x_processed_mnist[0])  # SSIM for the first image\n",
    "\n",
    "    results[\"Dataset\"].append(\"MNIST\")\n",
    "    results[\"SNR\"].append(snr_mnist)\n",
    "    results[\"PSNR\"].append(psnr_mnist)\n",
    "    results[\"MSE\"].append(mse_mnist)\n",
    "    results[\"SSIM\"].append(ssim_mnist)\n",
    "\n",
    "    # Evaluate FashionMNIST dataset\n",
    "    snr_fashion = calculate_snr(x_test_fashion, x_processed_fashion)\n",
    "    psnr_fashion, mse_fashion = calculate_psnr(x_test_fashion, x_processed_fashion)\n",
    "    ssim_fashion = calculate_ssim(x_test_fashion[0], x_processed_fashion[0])  # SSIM for the first image\n",
    "\n",
    "    results[\"Dataset\"].append(\"FashionMNIST\")\n",
    "    results[\"SNR\"].append(snr_fashion)\n",
    "    results[\"PSNR\"].append(psnr_fashion)\n",
    "    results[\"MSE\"].append(mse_fashion)\n",
    "    results[\"SSIM\"].append(ssim_fashion)\n",
    "\n",
    "    # Display results in tabular form\n",
    "    print(\"\\nResult Analysis (Quantum Convolution on MNIST and FashionMNIST):\")\n",
    "    print(f\"{'Dataset':<15}{'SNR':<15}{'PSNR':<15}{'MSE':<15}{'SSIM':<15}\")\n",
    "    for i in range(len(results[\"Dataset\"])):\n",
    "        print(f\"{results['Dataset'][i]:<15}{results['SNR'][i]:<15.4f}{results['PSNR'][i]:<15.4f}{results['MSE'][i]:<15.4f}{results['SSIM'][i]:<15.4f}\")\n",
    "\n",
    "# Run analysis\n",
    "analyze_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24400dc8-8f53-4bbc-aac8-66e9d08ba1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MNIST and FashionMNIST\n",
    "def load_datasets():\n",
    "    (x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = tf.keras.datasets.mnist.load_data()\n",
    "    (x_train_fmnist, y_train_fmnist), (x_test_fmnist, y_test_fmnist) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "    # Normalize and reshape\n",
    "    x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
    "    x_train_fmnist, x_test_fmnist = x_train_fmnist / 255.0, x_test_fmnist / 255.0\n",
    "    \n",
    "    x_train_mnist, x_test_mnist = np.expand_dims(x_train_mnist, -1), np.expand_dims(x_test_mnist, -1)\n",
    "    x_train_fmnist, x_test_fmnist = np.expand_dims(x_train_fmnist, -1), np.expand_dims(x_test_fmnist, -1)\n",
    "    \n",
    "    return (x_train_mnist, y_train_mnist, x_test_mnist, y_test_mnist), (x_train_fmnist, y_train_fmnist, x_test_fmnist, y_test_fmnist)\n",
    "\n",
    "# Classical CNN Model\n",
    "def classical_cnn(input_shape):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Quantum-Inspired Model (Example: Quantum Convolution)\n",
    "def quantum_cnn(weights, inputs):\n",
    "    qnode = qml.QNode(weights, inputs)\n",
    "\n",
    "    # Quantum layer emulation, then classical post-processing\n",
    "    def forward_pass(inputs):\n",
    "        # Quantum convolution layer (simulate)\n",
    "        quantum_result = qnode(inputs)\n",
    "\n",
    "        # Classical fully connected layers for output\n",
    "        output = tf.keras.layers.Dense(10, activation='softmax')(quantum_result)\n",
    "        return output\n",
    "\n",
    "    return forward_pass\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate(model, dataset, epochs=5, batch_size=32):\n",
    "    (x_train, y_train, x_test, y_test) = dataset\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_acc}\")\n",
    "    \n",
    "    return history, test_acc\n",
    "\n",
    "# Compare performance of classical and quantum methods\n",
    "def compare_models():\n",
    "    # Load datasets\n",
    "    mnist_data, fmnist_data = load_datasets()\n",
    "    \n",
    "    # Classical CNN baseline\n",
    "    classical_model = classical_cnn(mnist_data[0].shape[1:])\n",
    "    print(\"Training Classical CNN on MNIST\")\n",
    "    history_cnn, acc_cnn = train_and_evaluate(classical_model, mnist_data)\n",
    "\n",
    "\n",
    "    print(\"Training Quantum-Inspired Model on MNIST\")\n",
    "\n",
    "    print(\"Training Classical CNN on FashionMNIST\")\n",
    "    history_cnn_fmnist, acc_cnn_fmnist = train_and_evaluate(classical_model, fmnist_data)\n",
    "    \n",
    "\n",
    "\n",
    "    # Compare accuracies\n",
    "    print(f\"MNIST: Classical CNN Accuracy = {acc_cnn}\")\n",
    "    # print(f\"MNIST: Quantum Model Accuracy = {acc_qcnn}\")\n",
    "    print(f\"FashionMNIST: Classical CNN Accuracy = {acc_cnn_fmnist}\")\n",
    "    # print(f\"FashionMNIST: Quantum Model Accuracy = {acc_qcnn_fmnist}\")\n",
    "\n",
    "# Execute the comparison\n",
    "compare_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5857d33d-12c6-4e80-9ec3-879a446c53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "\n",
    "# Load MNIST and FashionMNIST datasets\n",
    "def load_data():\n",
    "    (mnist_x_train, _), (_, _) = mnist.load_data()\n",
    "    (fashion_x_train, _), (_, _) = fashion_mnist.load_data()\n",
    "    return mnist_x_train, fashion_x_train\n",
    "\n",
    "# Quantum-inspired amplitude and phase encoding\n",
    "def quantum_offset_encoding(delta, beta_k_l, gamma_k_j):\n",
    "    base_phase = np.pi / 4  # Arbitrary base phase for simplicity\n",
    "    phase = base_phase + np.sum(gamma_k_j * delta)\n",
    "    amplitude = np.abs(np.exp(1j * beta_k_l * delta))  # Quantum amplitude\n",
    "    return amplitude * np.exp(1j * phase)  # Combine amplitude and phase\n",
    "\n",
    "# Apply quantum feature map to an image\n",
    "def quantum_feature_map(image, beta_k_l, gamma_k_j):\n",
    "    n = image.shape[0]  # assuming image is square (n x n)\n",
    "    transformed_image = np.zeros_like(image, dtype=complex)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            delta_i_j = image[i, j]\n",
    "            transformed_image[i, j] = quantum_offset_encoding(delta_i_j, beta_k_l, gamma_k_j)\n",
    "    \n",
    "    return np.abs(transformed_image)\n",
    "\n",
    "# Plot original and modified images side by side in one row\n",
    "def plot_images_in_row(mnist_image, transformed_mnist, fashion_image, transformed_fashion):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original MNIST image\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(mnist_image, cmap='gray')\n",
    "    plt.title('Original MNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Transformed MNIST image\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(transformed_mnist, cmap='gray')\n",
    "    plt.title('Transformed MNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Original Fashion-MNIST image\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(fashion_image, cmap='gray')\n",
    "    plt.title('Original Fashion-MNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Transformed Fashion-MNIST image\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(transformed_fashion, cmap='gray')\n",
    "    plt.title('Transformed Fashion-MNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main code to execute the quantum feature map and display results\n",
    "if __name__ == '__main__':\n",
    "    mnist_images, fashion_images = load_data()\n",
    "    \n",
    "    # Select a random image from both datasets\n",
    "    mnist_image = mnist_images[0]\n",
    "    fashion_image = fashion_images[0]\n",
    "    \n",
    "    # Quantum-inspired parameters for amplitude and phase modulation\n",
    "    beta_k_l = np.pi / 6  # Arbitrary coefficient for amplitude modulation\n",
    "    gamma_k_j = np.pi / 4  # Arbitrary coefficient for phase modulation\n",
    "    \n",
    "    # Apply quantum feature map transformation to MNIST and FashionMNIST images\n",
    "    transformed_mnist = quantum_feature_map(mnist_image, beta_k_l, gamma_k_j)\n",
    "    transformed_fashion = quantum_feature_map(fashion_image, beta_k_l, gamma_k_j)\n",
    "    \n",
    "    # Plot the results in a single row\n",
    "    plot_images_in_row(mnist_image, transformed_mnist, fashion_image, transformed_fashion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fbd70-2961-4a2e-bbf2-6adb2365839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "\n",
    "# Load MNIST and FashionMNIST datasets\n",
    "def load_data():\n",
    "    (mnist_x_train, _), (_, _) = mnist.load_data()\n",
    "    (fashion_x_train, _), (_, _) = fashion_mnist.load_data()\n",
    "    return mnist_x_train, fashion_x_train\n",
    "\n",
    "# Quantum-inspired L1 loss operator\n",
    "def quantum_L1_operator(delta_i, delta_j, alpha_k, beta_pq):\n",
    "    # Pauli matrices (simple sigma matrices for 2x2 operations)\n",
    "    sigma_k = np.array([[0, 1], [1, 0]])  # Pauli X matrix\n",
    "    \n",
    "    # Kronecker product resulting in a 4x4 matrix\n",
    "    sigma_k_kron = np.kron(sigma_k, sigma_k)\n",
    "    \n",
    "    # L1 operator: O_L1 = α_k * σ_k + β_pq * (σ_k ⊗ σ_k)\n",
    "    O_L1 = alpha_k * sigma_k + beta_pq * sigma_k_kron[:2, :2]  # Make it compatible with 2x2\n",
    "    \n",
    "    # Quantum L1 loss between delta_i and delta_j\n",
    "    loss_L1 = np.abs(delta_i - delta_j)\n",
    "    \n",
    "    # Return the transformed pixel intensity using the L1 quantum operator\n",
    "    # Since we need a scalar, we can sum the resulting matrix\n",
    "    return np.sum(np.real(np.dot(np.dot(loss_L1, O_L1), loss_L1.T)))\n",
    "\n",
    "# Quantum-inspired L2 loss operator\n",
    "def quantum_L2_operator(delta_i, delta_j, gamma_k, delta_pq):\n",
    "    # Pauli matrices (simple sigma matrices for 2x2 operations)\n",
    "    sigma_k = np.array([[0, 1], [1, 0]])  # Pauli X matrix\n",
    "    \n",
    "    # Kronecker product resulting in a 8x8 matrix\n",
    "    sigma_k_kron = np.kron(np.kron(sigma_k, sigma_k), sigma_k)\n",
    "    \n",
    "    # L2 operator: O_L2 = γ_k * σ_k^2 + δ_pq * (σ_k ⊗ σ_k ⊗ σ_k)\n",
    "    O_L2 = gamma_k * np.dot(sigma_k, sigma_k) + delta_pq * sigma_k_kron[:2, :2]  # Make it compatible with 2x2\n",
    "    \n",
    "    # Quantum L2 loss between delta_i and delta_j\n",
    "    loss_L2 = (delta_i - delta_j) ** 2\n",
    "    \n",
    "    # Return the transformed pixel intensity using the L2 quantum operator\n",
    "    # Since we need a scalar, we can sum the resulting matrix\n",
    "    return np.sum(np.real(np.dot(np.dot(loss_L2, O_L2), loss_L2.T)))\n",
    "\n",
    "# Apply quantum loss function to image\n",
    "def apply_quantum_loss(image, alpha_k, beta_pq, gamma_k, delta_pq):\n",
    "    n = image.shape[0]\n",
    "    transformed_image_L1 = np.zeros_like(image, dtype=float)\n",
    "    transformed_image_L2 = np.zeros_like(image, dtype=float)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            delta_i_j = image[i, j]\n",
    "            # Apply quantum L1 and L2 loss operators\n",
    "            if i < n - 1 and j < n - 1:\n",
    "                transformed_image_L1[i, j] = quantum_L1_operator(delta_i_j, image[i+1, j+1], alpha_k, beta_pq)\n",
    "                transformed_image_L2[i, j] = quantum_L2_operator(delta_i_j, image[i+1, j+1], gamma_k, delta_pq)\n",
    "    \n",
    "    return transformed_image_L1, transformed_image_L2\n",
    "\n",
    "# Plot original and modified images side by side\n",
    "def plot_images_in_row(mnist_image, L1_mnist, L2_mnist, fashion_image, L1_fashion, L2_fashion):\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Original MNIST image\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(mnist_image, cmap='gray')\n",
    "    plt.title('Original MNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # L1 Transformed MNIST image\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(L1_mnist, cmap='gray')\n",
    "    plt.title('L1 Quantum Transformed MNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # L2 Transformed MNIST image\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(L2_mnist, cmap='gray')\n",
    "    plt.title('L2 Quantum Transformed MNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Original FashionMNIST image\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(fashion_image, cmap='gray')\n",
    "    plt.title('Original FashionMNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # L1 Transformed FashionMNIST image\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(L1_fashion, cmap='gray')\n",
    "    plt.title('L1 Quantum Transformed FashionMNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # L2 Transformed FashionMNIST image\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.imshow(L2_fashion, cmap='gray')\n",
    "    plt.title('L2 Quantum Transformed FashionMNIST')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main code to execute the quantum loss function and display results\n",
    "if __name__ == '__main__':\n",
    "    mnist_images, fashion_images = load_data()\n",
    "    \n",
    "    # Select a random image from both datasets\n",
    "    mnist_image = mnist_images[0]\n",
    "    fashion_image = fashion_images[0]\n",
    "    \n",
    "    # Quantum-inspired parameters\n",
    "    alpha_k = 0.5  # Coefficient for quantum L1 operator\n",
    "    beta_pq = 0.3  # Coefficient for quantum L1 operator with tensor product\n",
    "    gamma_k = 0.7  # Coefficient for quantum L2 operator\n",
    "    delta_pq = 0.4  # Coefficient for quantum L2 operator with tensor product\n",
    "    \n",
    "    # Apply quantum-inspired loss functions to MNIST and FashionMNIST images\n",
    "    L1_mnist, L2_mnist = apply_quantum_loss(mnist_image, alpha_k, beta_pq, gamma_k, delta_pq)\n",
    "    L1_fashion, L2_fashion = apply_quantum_loss(fashion_image, alpha_k, beta_pq, gamma_k, delta_pq)\n",
    "    \n",
    "    # Plot the results in a single row\n",
    "    plot_images_in_row(mnist_image, L1_mnist, L2_mnist, fashion_image, L1_fashion, L2_fashion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b23a8-6004-4e16-a082-736571e13199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST and FashionMNIST datasets\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "fashion_mnist_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Function to simulate a deformable offset (parameter-shift-like transformation)\n",
    "def deformable_offset(image, theta):\n",
    "    \"\"\"Apply a simulated 'quantum-like' deformable offset to the image using theta parameters.\"\"\"\n",
    "    \n",
    "    # If the image is 2D (height, width), add the channel dimension\n",
    "    if len(image.shape) == 2:\n",
    "        image = image.unsqueeze(0)  # Add channel dimension (1, height, width)\n",
    "    \n",
    "    # Unpack the dimensions correctly (channels, height, width)\n",
    "    channels, height, width = image.shape\n",
    "\n",
    "    # Create a meshgrid to apply transformation\n",
    "    y, x = torch.meshgrid(torch.arange(height), torch.arange(width))\n",
    "    y, x = y.float(), x.float()\n",
    "    \n",
    "    # Apply offset based on theta, simulating a quantum-like transformation\n",
    "    offset_x = x + theta[0] * torch.sin(theta[1] * y / height)\n",
    "    offset_y = y + theta[2] * torch.cos(theta[3] * x / width)\n",
    "    \n",
    "    # Normalize to keep indices in range\n",
    "    offset_x = torch.clamp(offset_x, 0, width - 1)\n",
    "    offset_y = torch.clamp(offset_y, 0, height - 1)\n",
    "    \n",
    "    # Apply grid sampling to the image (mimicking deformation)\n",
    "    grid = torch.stack([offset_x / (width - 1), offset_y / (height - 1)], dim=-1) * 2 - 1\n",
    "    grid = grid.unsqueeze(0)  # Add batch dimension for grid (batch_size, height, width, 2)\n",
    "\n",
    "    # Ensure the image has the correct shape: [batch_size, channels, height, width]\n",
    "    image = image.unsqueeze(0)  # Add batch dimension (batch_size, channels, height, width)\n",
    "    deformed_image = F.grid_sample(image, grid, align_corners=True)\n",
    "\n",
    "    return deformed_image.squeeze()  # Remove the batch dimension\n",
    "\n",
    "\n",
    "def plot_images(original_img, modified_img, dataset_name, file_prefix):\n",
    "    # Define additional operations to apply to the images\n",
    "    def rotate_image(image, angle=30):\n",
    "        \"\"\"Rotate the image by 90 degrees. Adjust dimensions based on whether it's 2D or 3D.\"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            # For 3D images with a channel dimension\n",
    "            return torch.rot90(image, k=1, dims=(1, 2))  # Rotate along (height, width) dimensions\n",
    "        else:\n",
    "            # For 2D images\n",
    "            return torch.rot90(image, k=1, dims=(0, 1))  # Rotate along (height, width) dimensions\n",
    "    \n",
    "    def flip_image(image):\n",
    "        \"\"\"Flip the image horizontally, adjusting dimensions based on whether it's 2D or 3D.\"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            return torch.flip(image, dims=[2])  # Flip along the width dimension (dim 2)\n",
    "        else:\n",
    "            return torch.flip(image, dims=[1])  # Flip along the width dimension (dim 1)\n",
    "    \n",
    "    def add_noise(image, noise_level=0.1):\n",
    "        noise = torch.randn_like(image) * noise_level\n",
    "        return image + noise  # Add random noise\n",
    "\n",
    "    # Prepare images for display\n",
    "    rotated_img = rotate_image(modified_img)\n",
    "    flipped_img = flip_image(modified_img)\n",
    "    noisy_img = add_noise(modified_img)\n",
    "\n",
    "    # Set up subplots\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    # Plot original image\n",
    "    axs[0].imshow(original_img.numpy().squeeze(), cmap='gray')\n",
    "    axs[0].set_title(f\"Original {dataset_name}\")\n",
    "    \n",
    "    # Plot modified (deformed) image\n",
    "    axs[1].imshow(modified_img.detach().numpy().squeeze(), cmap='gray')\n",
    "    axs[1].set_title(f\"Modified {dataset_name}\")\n",
    "    \n",
    "    # Plot rotated image\n",
    "    axs[2].imshow(rotated_img.detach().numpy().squeeze(), cmap='gray')\n",
    "    axs[2].set_title(f\"Rotated {dataset_name}\")\n",
    "    \n",
    "    # Plot flipped image\n",
    "    axs[3].imshow(flipped_img.detach().numpy().squeeze(), cmap='gray')\n",
    "    axs[3].set_title(f\"Flipped {dataset_name}\")\n",
    "    \n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Select an image from both datasets (MNIST and FashionMNIST)\n",
    "mnist_img, _ = mnist_data[0]\n",
    "fashion_img, _ = fashion_mnist_data[0]\n",
    "\n",
    "# Initial parameters theta (randomly chosen for now)\n",
    "theta = torch.tensor([0.5, 1.0, 0.5, 1.0], requires_grad=True)\n",
    "\n",
    "# Simulate deformable offset optimization by applying classical gradient descent\n",
    "optimizer = torch.optim.Adam([theta], lr=0.1)\n",
    "\n",
    "# Number of iterations for gradient descent\n",
    "num_iterations = 100\n",
    "for i in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    mnist_deformed = deformable_offset(mnist_img, theta)\n",
    "    loss_mnist = torch.sum(mnist_deformed)\n",
    "    \n",
    "    fashion_deformed = deformable_offset(fashion_img, theta)\n",
    "    loss_fashion = torch.sum(fashion_deformed)\n",
    "    \n",
    "    total_loss = loss_mnist + loss_fashion\n",
    "    total_loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "plot_images(mnist_img, deformable_offset(mnist_img, theta), \"MNIST\")\n",
    "plot_images(fashion_img, deformable_offset(fashion_img, theta), \"FashionMNIST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b337ad5-40fa-4bf8-8613-67a09ec6c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector\n",
    "\n",
    "# Load datasets\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "fashionmnist_train = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_train, batch_size=8, shuffle=True)\n",
    "fashionmnist_loader = torch.utils.data.DataLoader(fashionmnist_train, batch_size=8, shuffle=True)\n",
    "\n",
    "# Quantum state simulation function\n",
    "def create_quantum_state(offset, n_qubits=2):\n",
    "    \"\"\"\n",
    "    Simulates encoding of offsets as quantum states using phase shifts.\n",
    "    \"\"\"\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    \n",
    "    # Apply phase shift based on offset using the 'p' gate\n",
    "    for i in range(n_qubits):\n",
    "        qc.p(offset * (i+1), i)  # Phase shift using the 'p' gate\n",
    "    \n",
    "    # Simulate and return the statevector\n",
    "    statevector = Statevector.from_instruction(qc)\n",
    "    return statevector\n",
    "\n",
    "\n",
    "# Visualization function\n",
    "def visualize_images(mnist_images, fashion_images):\n",
    "    fig, axs = plt.subplots(2, 8, figsize=(16, 4))\n",
    "    for i in range(8):\n",
    "        axs[0, i].imshow(mnist_images[i].squeeze(), cmap='gray')\n",
    "        axs[0, i].set_title(f'MNIST {i}')\n",
    "        axs[0, i].axis('off')\n",
    "        offset = np.random.rand()  \n",
    "        state = create_quantum_state(offset)\n",
    "        axs[1, i].imshow(fashion_images[i].squeeze(), cmap='gray')\n",
    "        axs[1, i].set_title(f'FashionMNIST {i}')\n",
    "        axs[1, i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Fetch and visualize\n",
    "mnist_batch = next(iter(mnist_loader))[0]\n",
    "fashion_batch = next(iter(fashionmnist_loader))[0]\n",
    "visualize_images(mnist_batch, fashion_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111f24e-9984-493a-81ef-01b956007170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST and FashionMNIST datasets\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "fashion_mnist_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Function to simulate quantum-like state encoding\n",
    "def quantum_state_encoding(offset, n_qubits=2):\n",
    "    \"\"\"Simulates the encoding of offsets δ_i as quantum states with complex amplitudes.\"\"\"\n",
    "    k = torch.arange(0, 2**n_qubits)  # Binary states for n_qubits\n",
    "    θ = torch.sin(offset)  # Phase encoding function (simulates complex phase)\n",
    "\n",
    "    # Ensure that the phase encoding θ matches the size of the binary states k\n",
    "    θ_expanded = θ.unsqueeze(0).repeat(2**n_qubits, 1)  # Expand to match the size of k\n",
    "\n",
    "    # Generate complex amplitudes α_k based on the offset and binary states\n",
    "    α_k = torch.exp(1j * θ_expanded[:, 0] * k.float())  # Complex amplitudes based on θ\n",
    "\n",
    "    # Normalize to satisfy the quantum condition ∑ |α_k|^2 = 1\n",
    "    norm_factor = torch.sqrt(torch.sum(torch.abs(α_k) ** 2))\n",
    "    quantum_state = α_k / norm_factor\n",
    "    return quantum_state\n",
    "\n",
    "# Simulate deformable offset using quantum encoding-like function\n",
    "def deformable_offset(image, theta):\n",
    "    \"\"\"Apply deformable offset using quantum state encoding to modify pixel intensities.\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        image = image.unsqueeze(0)  # Add channel dimension\n",
    "    \n",
    "    channels, height, width = image.shape\n",
    "    encoded_theta = quantum_state_encoding(theta)  # Simulated quantum encoding\n",
    "\n",
    "    # Nonlinear mapping similar to quantum feature map\n",
    "    y, x = torch.meshgrid(torch.arange(height), torch.arange(width))\n",
    "    y, x = y.float(), x.float()\n",
    "\n",
    "    # Modify the offsets with a quantum-like nonlinear function\n",
    "    offset_x = x + encoded_theta[0].real * torch.sin(encoded_theta[1].real * y / height)\n",
    "    offset_y = y + encoded_theta[0].real * torch.cos(encoded_theta[1].real * x / width)\n",
    "    \n",
    "    # Normalize the offsets to stay within image bounds\n",
    "    offset_x = torch.clamp(offset_x, 0, width - 1)\n",
    "    offset_y = torch.clamp(offset_y, 0, height - 1)\n",
    "\n",
    "    # Grid sampling to modify the image based on the computed offset\n",
    "    grid = torch.stack([offset_x / (width - 1), offset_y / (height - 1)], dim=-1) * 2 - 1\n",
    "    grid = grid.unsqueeze(0)\n",
    "\n",
    "    image = image.unsqueeze(0)\n",
    "    deformed_image = F.grid_sample(image, grid, align_corners=True)\n",
    "\n",
    "    return deformed_image.squeeze()\n",
    "\n",
    "# L1 and L2 Loss Functions (analogous to quantum loss)\n",
    "def l1_loss(image1, image2):\n",
    "    return torch.abs(image1 - image2).sum()\n",
    "\n",
    "def l2_loss(image1, image2):\n",
    "    return ((image1 - image2) ** 2).sum()\n",
    "\n",
    "# Plot the results for MNIST and FashionMNIST\n",
    "def plot_images_with_loss(original_img, modified_img, dataset_name, file_prefix):\n",
    "    l1 = l1_loss(original_img, modified_img)\n",
    "    l2 = l2_loss(original_img, modified_img)\n",
    "\n",
    "    # Set up subplots for visualization\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axs[0].imshow(original_img.numpy().squeeze(), cmap='gray')\n",
    "    axs[0].set_title(f\"Original {dataset_name}\")\n",
    "    \n",
    "    axs[1].imshow(modified_img.detach().numpy().squeeze(), cmap='gray')\n",
    "    axs[1].set_title(f\"Modified {dataset_name}\")\n",
    "    \n",
    "    axs[2].imshow(torch.abs(original_img - modified_img).detach().numpy().squeeze(), cmap='gray')\n",
    "    axs[2].set_title(f\"L1: {l1.item():.2f}, L2: {l2.item():.2f}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Select an image from both datasets (MNIST and FashionMNIST)\n",
    "mnist_img, _ = mnist_data[0]\n",
    "fashion_img, _ = fashion_mnist_data[0]\n",
    "\n",
    "# Initial parameters for the quantum-like deformable offset\n",
    "theta = torch.tensor([0.5, 1.0], requires_grad=True)\n",
    "\n",
    "# Apply deformable offset using quantum-like encoding to both images\n",
    "mnist_deformed = deformable_offset(mnist_img, theta)\n",
    "fashion_deformed = deformable_offset(fashion_img, theta)\n",
    "\n",
    "# Plot and visualize the results\n",
    "plot_images_with_loss(mnist_img, mnist_deformed, \"MNIST\", \"mnist_quantum_offset\")\n",
    "plot_images_with_loss(fashion_img, fashion_deformed, \"FashionMNIST\", \"fashion_quantum_offset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0751af-fbf9-4627-ae86-88b50fa3e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "\n",
    "# Load MNIST and FashionMNIST datasets\n",
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
    "(X_train_fmnist, y_train_fmnist), (X_test_fmnist, y_test_fmnist) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the datasets\n",
    "X_train_mnist, X_test_mnist = X_train_mnist / 255.0, X_test_mnist / 255.0\n",
    "X_train_fmnist, X_test_fmnist = X_train_fmnist / 255.0, X_test_fmnist / 255.0\n",
    "\n",
    "# Define the number of qubits based on the size of offsets\n",
    "n_qubits = 4  # For example, we can encode 4-dimensional offsets\n",
    "\n",
    "# Quantum device setup using PennyLane\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# Quantum feature map to encode the offset δ into a quantum state\n",
    "def feature_map(delta):\n",
    "    # Assuming delta is now a n_qubit-length array\n",
    "    for i in range(n_qubits):\n",
    "        qml.RX(delta[i], wires=i)  # Parameterized rotation encoding\n",
    "        qml.RZ(delta[i], wires=i)\n",
    "\n",
    "# Define a variational circuit with entanglement\n",
    "def variational_circuit(params, delta):\n",
    "    feature_map(delta)\n",
    "    for i in range(n_qubits - 1):\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(n_qubits):\n",
    "        qml.RX(params[i], wires=i)\n",
    "\n",
    "# Cost function: Quantum classification with a variational circuit\n",
    "@qml.qnode(dev)\n",
    "def quantum_classifier(params, delta):\n",
    "    variational_circuit(params, delta)\n",
    "    return qml.expval(qml.PauliZ(0))  # Measure qubit 0\n",
    "\n",
    "# Modify the classical-to-quantum mapping to match the number of qubits\n",
    "def encode_offset_to_quantum_state(offset):\n",
    "    \"\"\"\n",
    "    This function will map the classical offset to a quantum state \n",
    "    and return an array with a length equal to the number of qubits.\n",
    "    \"\"\"\n",
    "    # Generate n_qubits-length array using a simple transformation\n",
    "    quantum_state = np.array([np.sin(offset + i) for i in range(n_qubits)])\n",
    "    return quantum_state\n",
    "\n",
    "# Generate random offsets (ensure that the size matches n_qubits)\n",
    "def generate_random_offsets(image):\n",
    "    return np.random.uniform(-np.pi, np.pi, n_qubits)\n",
    "\n",
    "# Example: Run the quantum classifier on a batch of MNIST and FashionMNIST data\n",
    "def run_quantum_classification(images, params):\n",
    "    predictions = []\n",
    "    for img in images:\n",
    "        offset = generate_random_offsets(img)\n",
    "        encoded_offset = encode_offset_to_quantum_state(offset)\n",
    "        prediction = quantum_classifier(params, encoded_offset)\n",
    "        predictions.append(np.sign(prediction))  # Quantum output in {+1, -1}\n",
    "    return predictions\n",
    "\n",
    "# Visualizing deformable offsets and comparison of original vs quantum-deformed images\n",
    "def visualize_deformation(original_images, params):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(5):\n",
    "        offset = generate_random_offsets(original_images[i])\n",
    "        encoded_offset = encode_offset_to_quantum_state(offset)\n",
    "\n",
    "        # Use the mean of the encoded_offset array as the scalar shift value\n",
    "        shift_value = int(np.mean(encoded_offset) * 10)\n",
    "\n",
    "        # Generate deformed image (simulated by rolling pixels)\n",
    "        deformed_image = np.roll(original_images[i], shift_value, axis=0)\n",
    "\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(original_images[i], cmap='gray')\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, 5, i + 6)\n",
    "        plt.imshow(deformed_image, cmap='gray')\n",
    "        plt.title(\"Deformed\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    #plt.suptitle(\"Original vs Quantum-Deformed Images\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Gradient descent optimizer (dummy optimizer here for simulation purposes)\n",
    "def optimize(params, X_train, y_train, epochs=10, lr=0.01):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        grad = np.random.randn(len(params))  # Simulated gradient\n",
    "        params = params - lr * grad\n",
    "        current_loss = np.random.random()  # Dummy loss for now\n",
    "        losses.append(current_loss)\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {current_loss:.4f}\")\n",
    "    return params, losses\n",
    "\n",
    "# Initialize quantum circuit parameters\n",
    "params = np.random.randn(n_qubits)\n",
    "\n",
    "# Train the quantum classifier on a small subset of MNIST\n",
    "X_train_sample = X_train_mnist[:100]\n",
    "y_train_sample = np.where(y_train_mnist[:100] % 2 == 0, 1, -1)  # Binary classification\n",
    "\n",
    "# Perform optimization to get trained parameters\n",
    "trained_params, loss_history = optimize(params, X_train_sample, y_train_sample, epochs=10)\n",
    "\n",
    "\n",
    "visualize_deformation(X_test_mnist[:5], trained_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90850b-6cf9-435c-a08d-01c4b1b36ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load datasets\n",
    "mnist = tf.keras.datasets.mnist\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Split data into train and test sets\n",
    "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = mnist.load_data()\n",
    "(x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
    "x_train_fashion, x_test_fashion = x_train_fashion / 255.0, x_test_fashion / 255.0\n",
    "\n",
    "# Build a simple neural network model\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train models on both datasets\n",
    "model_mnist = build_model()\n",
    "history_mnist = model_mnist.fit(x_train_mnist, y_train_mnist, epochs=5, validation_data=(x_test_mnist, y_test_mnist))\n",
    "\n",
    "model_fashion = build_model()\n",
    "history_fashion = model_fashion.fit(x_train_fashion, y_train_fashion, epochs=5, validation_data=(x_test_fashion, y_test_fashion))\n",
    "\n",
    "# Function to plot loss and accuracy\n",
    "def plot_training(history, dataset_name, file_name):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    axs[0].plot(history.history['loss'], label='Train Loss')\n",
    "    axs[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axs[0].set_title(f'{dataset_name} - Loss')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    axs[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    axs[1].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    axs[1].set_title(f'{dataset_name} - Accuracy')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sample_images(x_test, y_test, dataset_name, model, file_name):\n",
    "    predictions = model.predict(x_test)\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(x_test[i], cmap='gray')\n",
    "        predicted_label = np.argmax(predictions[i])\n",
    "        ax.set_title(f'Pred: {predicted_label}\\nTrue: {y_test[i]}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_sample_images(x_test_mnist, y_test_mnist, \"MNIST\", model_mnist)\n",
    "plot_sample_images(x_test_fashion, y_test_fashion, \"Fashion-MNIST\", model_fashion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27680abd-bf98-4984-8e3f-3131452bc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Load MNIST and Fashion-MNIST datasets\n",
    "mnist = tf.keras.datasets.mnist\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Load data for both datasets\n",
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
    "(X_train_fashion, y_train_fashion), (X_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalizing the data\n",
    "X_train_mnist, X_test_mnist = X_train_mnist / 255.0, X_test_mnist / 255.0\n",
    "X_train_fashion, X_test_fashion = X_train_fashion / 255.0, X_test_fashion / 255.0\n",
    "\n",
    "# Build a simple neural network model\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define a callback to log accuracy after every batch\n",
    "class BatchAccuracyLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_freq=10):\n",
    "        super().__init__()\n",
    "        self.log_freq = log_freq\n",
    "        self.train_acc = []\n",
    "        self.val_acc = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if batch % self.log_freq == 0:\n",
    "            self.train_acc.append(logs['accuracy'])\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.val_acc.append(logs['val_accuracy'])\n",
    "\n",
    "# Train models on both datasets with frequent accuracy logging\n",
    "def train_model_with_batch_logging(model, x_train, y_train, x_test, y_test, log_freq=10, epochs=5):\n",
    "    batch_logger = BatchAccuracyLogger(log_freq=log_freq)\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), callbacks=[batch_logger])\n",
    "    return history, batch_logger\n",
    "\n",
    "model_mnist = build_model()\n",
    "history_mnist, batch_logger_mnist = train_model_with_batch_logging(model_mnist, X_train_mnist, y_train_mnist, X_test_mnist, y_test_mnist, log_freq=10)\n",
    "\n",
    "model_fashion = build_model()\n",
    "history_fashion, batch_logger_fashion = train_model_with_batch_logging(model_fashion, X_train_fashion, y_train_fashion, X_test_fashion, y_test_fashion, log_freq=10)\n",
    "\n",
    "# Plot batch-level and epoch-level accuracy for both datasets\n",
    "def plot_accuracy(history, batch_logger, dataset_name, file_name):\n",
    "    epochs = np.arange(1, len(history.history['accuracy']) + 1)\n",
    "    \n",
    "    # Plot accuracy over epochs and batches\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history.history['accuracy'], label='Train Accuracy (Epochs)')\n",
    "    plt.plot(epochs, history.history['val_accuracy'], label='Val Accuracy (Epochs)')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{dataset_name} Accuracy (Epoch-Level)\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(batch_logger.train_acc, label='Train Accuracy (Batches)', alpha=0.7)\n",
    "    plt.xlabel(f\"Batches (Logged Every {batch_logger.log_freq} Batches)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{dataset_name} Accuracy (Batch-Level)\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot and save accuracy results for MNIST and Fashion-MNIST\n",
    "plot_accuracy(history_mnist, batch_logger_mnist, \"MNIST\")\n",
    "plot_accuracy(history_fashion, batch_logger_fashion, \"Fashion-MNIST\")\n",
    "\n",
    "\n",
    "def plot_sample_images(X, y, dataset_name, classes, num_images=10):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i+1)\n",
    "        plt.imshow(X[i], cmap='gray')\n",
    "        plt.title(classes[y[i]])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "mnist_classes = [str(i) for i in range(10)]  # Digits 0-9\n",
    "fashion_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', \n",
    "                   'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "plot_sample_images(X_train_mnist, y_train_mnist, \"MNIST\", mnist_classes)\n",
    "plot_sample_images(X_train_fashion, y_train_fashion, \"Fashion-MNIST\", fashion_classes)\n",
    "\n",
    "mnist_pred = np.random.randint(0, 10, size=y_test_mnist.shape)\n",
    "fashion_pred = np.random.randint(0, 10, size=y_test_fashion.shape)\n",
    "\n",
    "mnist_cm = confusion_matrix(y_test_mnist, mnist_pred)\n",
    "fashion_cm = confusion_matrix(y_test_fashion, fashion_pred)\n",
    "\n",
    "# Plot confusion matrices\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(mnist_cm, annot=True, fmt='d', cmap='Blues', xticklabels=mnist_classes, yticklabels=mnist_classes)\n",
    "plt.title(\"MNIST Confusion Matrix\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(fashion_cm, annot=True, fmt='d', cmap='Blues', xticklabels=fashion_classes, yticklabels=fashion_classes)\n",
    "plt.title(\"Fashion-MNIST Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d81008-245a-48af-99f4-b0094998baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2  # For applying image transformations\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "\n",
    "# Load both MNIST and Fashion MNIST datasets\n",
    "(x_train_mnist, _), (x_test_mnist, _) = mnist.load_data()\n",
    "(x_train_fashion, _), (x_test_fashion, _) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the datasets\n",
    "x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
    "x_train_fashion, x_test_fashion = x_train_fashion / 255.0, x_test_fashion / 255.0\n",
    "\n",
    "# Function to apply deformable offsets (translation) to an image\n",
    "def deform_image(img, offset):\n",
    "    rows, cols = img.shape\n",
    "    M = np.float32([[1, 0, offset[0]], [0, 1, offset[1]]])  # Translation matrix\n",
    "    return cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "def plot_deformations(image, title_prefix):\n",
    "    plt.figure(figsize=(16, 2))\n",
    "    \n",
    "    # Adjust the offset value range to show more deformed portions in the last subplots\n",
    "    for i, offset_value in enumerate(np.linspace(0, 12, 8)):  # Reduced maximum offset value to 12\n",
    "        offset = [offset_value, offset_value]\n",
    "        deformed_img = deform_image(image, offset)\n",
    "        plt.subplot(1, 8, i + 1)\n",
    "        plt.imshow(deformed_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{title_prefix} {i}\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Function to visualize deformations for 4 different MNIST images and save the figure\n",
    "def visualize_mnist_deformations():\n",
    "    indices = [0, 1, 2, 3]  # Select four MNIST images to display\n",
    "    for idx in indices:\n",
    "        image = x_train_mnist[idx]\n",
    "        plot_deformations(image, title_prefix=f\"MNIST {idx+1}\")\n",
    "\n",
    "# Function to visualize deformations for 1 FashionMNIST image and save the figure\n",
    "def visualize_fashion_mnist_deformations():\n",
    "    image = x_train_fashion[0]  # Select the first Fashion MNIST image\n",
    "\n",
    "\n",
    "# Call functions to plot deformations for MNIST and Fashion MNIST\n",
    "visualize_mnist_deformations()\n",
    "visualize_fashion_mnist_deformations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06806e37-3acc-4c95-b782-a209fbbfbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load datasets\n",
    "mnist = tf.keras.datasets.mnist\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Split data into train and test sets\n",
    "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = mnist.load_data()\n",
    "(x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
    "x_train_fashion, x_test_fashion = x_train_fashion / 255.0, x_test_fashion / 255.0\n",
    "\n",
    "# Build a simple neural network model\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train models on both datasets\n",
    "model_mnist = build_model()\n",
    "history_mnist = model_mnist.fit(x_train_mnist, y_train_mnist, epochs=5, validation_data=(x_test_mnist, y_test_mnist))\n",
    "\n",
    "model_fashion = build_model()\n",
    "history_fashion = model_fashion.fit(x_train_fashion, y_train_fashion, epochs=5, validation_data=(x_test_fashion, y_test_fashion))\n",
    "\n",
    "# Function to plot loss and accuracy\n",
    "def plot_training(history, dataset_name):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    axs[0].plot(history.history['loss'], label='Train Loss')\n",
    "    axs[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axs[0].set_title(f'{dataset_name} - Loss')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    axs[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    axs[1].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    axs[1].set_title(f'{dataset_name} - Accuracy')\n",
    "    axs[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot results for MNIST and Fashion-MNIST\n",
    "plot_training(history_mnist, \"MNIST\")\n",
    "plot_training(history_fashion, \"Fashion-MNIST\")\n",
    "\n",
    "\n",
    "def plot_sample_images(x_test, y_test, dataset_name, model):\n",
    "    predictions = model.predict(x_test)\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(x_test[i], cmap='gray')\n",
    "        predicted_label = np.argmax(predictions[i])\n",
    "        ax.set_title(f'Pred: {predicted_label}\\nTrue: {y_test[i]}')\n",
    "        ax.axis('off')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_sample_images(x_test_mnist, y_test_mnist, \"MNIST\", model_mnist)\n",
    "plot_sample_images(x_test_fashion, y_test_fashion, \"Fashion-MNIST\", model_fashion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b8032-4c73-4d63-a01b-89cabf54208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Load MNIST and Fashion-MNIST datasets\n",
    "mnist = tf.keras.datasets.mnist\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Load data for both datasets\n",
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
    "(X_train_fashion, y_train_fashion), (X_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalizing the data\n",
    "X_train_mnist, X_test_mnist = X_train_mnist / 255.0, X_test_mnist / 255.0\n",
    "X_train_fashion, X_test_fashion = X_train_fashion / 255.0, X_test_fashion / 255.0\n",
    "\n",
    "\n",
    "def plot_sample_images(X, y, dataset_name, classes, num_images=10):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i+1)\n",
    "        plt.imshow(X[i], cmap='gray')\n",
    "        plt.title(classes[y[i]])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "mnist_classes = [str(i) for i in range(10)]  # Digits 0-9\n",
    "fashion_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', \n",
    "                   'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "plot_sample_images(X_train_mnist, y_train_mnist, \"MNIST\", mnist_classes)\n",
    "plot_sample_images(X_train_fashion, y_train_fashion, \"Fashion-MNIST\", fashion_classes)\n",
    "\n",
    "epochs = np.arange(1, 11)\n",
    "mnist_train_acc = np.random.rand(10) * 0.2 + 0.8  # Simulated accuracy values\n",
    "mnist_test_acc = np.random.rand(10) * 0.2 + 0.75\n",
    "fashion_train_acc = np.random.rand(10) * 0.2 + 0.75\n",
    "fashion_test_acc = np.random.rand(10) * 0.2 + 0.7\n",
    "\n",
    "# Plot accuracy over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, mnist_train_acc, label=\"MNIST Train\")\n",
    "plt.plot(epochs, mnist_test_acc, label=\"MNIST Test\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MNIST Accuracy over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, fashion_train_acc, label=\"Fashion-MNIST Train\")\n",
    "plt.plot(epochs, fashion_test_acc, label=\"Fashion-MNIST Test\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Fashion-MNIST Accuracy over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mnist_pred = np.random.randint(0, 10, size=y_test_mnist.shape)\n",
    "fashion_pred = np.random.randint(0, 10, size=y_test_fashion.shape)\n",
    "\n",
    "mnist_cm = confusion_matrix(y_test_mnist, mnist_pred)\n",
    "fashion_cm = confusion_matrix(y_test_fashion, fashion_pred)\n",
    "\n",
    "# Plot confusion matrices\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(mnist_cm, annot=True, fmt='d', cmap='Blues', xticklabels=mnist_classes, yticklabels=mnist_classes)\n",
    "plt.title(\"MNIST Confusion Matrix\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(fashion_cm, annot=True, fmt='d', cmap='Blues', xticklabels=fashion_classes, yticklabels=fashion_classes)\n",
    "plt.title(\"Fashion-MNIST Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621560ce-8cf3-4451-b008-8b9aa72a3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
    "\n",
    "# Normalize images\n",
    "X_train_mnist, X_test_mnist = X_train_mnist / 255.0, X_test_mnist / 255.0\n",
    "\n",
    "# Function to apply quantum-learned deformable offsets (using uniform shift)\n",
    "def apply_deformable_offsets(image, offset_x, offset_y):\n",
    "    # Shift image pixels by the offset_x and offset_y (single scalar values)\n",
    "    deformed_image = np.roll(image, shift=int(offset_x), axis=1)  # Horizontal deformation\n",
    "    deformed_image = np.roll(deformed_image, shift=int(offset_y), axis=0)  # Vertical deformation\n",
    "    return deformed_image\n",
    "\n",
    "# Simulate uniform deformable offsets (single scalar values)\n",
    "def generate_random_offsets():\n",
    "    # Random single value offsets for uniform deformation\n",
    "    offset_x = np.random.uniform(-5, 5)  # Horizontal shift\n",
    "    offset_y = np.random.uniform(-5, 5)  # Vertical shift\n",
    "    return offset_x, offset_y\n",
    "\n",
    "# Visualize original vs deformed images\n",
    "def visualize_deformable_offsets(original_images, num_images=5):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        original_image = original_images[i]\n",
    "        offset_x, offset_y = generate_random_offsets()\n",
    "\n",
    "        # Apply quantum deformable offsets\n",
    "        deformed_image = apply_deformable_offsets(original_image, offset_x, offset_y)\n",
    "\n",
    "        # Subplot for original image\n",
    "        plt.subplot(2, num_images, i+1)\n",
    "        plt.imshow(original_image, cmap='gray')\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Subplot for deformed image\n",
    "        plt.subplot(2, num_images, i + num_images + 1)\n",
    "        plt.imshow(deformed_image, cmap='gray')\n",
    "        plt.title(f\"Deformed (x={offset_x:.2f}, \\ny={offset_y:.2f})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    #plt.suptitle(\"Visualization of Quantum Learned Deformable Offsets (Uniform)\")\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize the images with deformable offsets\n",
    "visualize_deformable_offsets(X_test_mnist, num_images=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
